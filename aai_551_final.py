# -*- coding: utf-8 -*-
"""AAI_551 final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IdYYqiBa4UELYGNv8OrvUfotoxStOtVn

**Final Project AAI-551**

Name : Brinda Nathvani , CWID - (20011268)

Name : Saumil Trivedi  , CWID - (20011349)

**Introduction:**

1. In this project, we build Convolutional Neural Network to classify CIFAR-10 Images.
2. We can directly load dataset from many deep learning packages.
3. We can use any deep learning packages such as pytorch, keras or tensorflow for this project.

## **Data analysis on CIFAR-10 Dataset**

###  Loading the  data
"""

# Load Cifar-10 Data
# This is just an example, you may load dataset from other packages.
import keras
import numpy as np
import tensorflow.keras

### If you can not load keras dataset, un-comment these two lines.
#import ssl
#ssl._create_default_https_context = ssl._create_unverified_context

(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

print('shape of x_train: ' + str(x_train.shape))
print('shape of y_train: ' + str(y_train.shape))
print('shape of x_test: ' + str(x_test.shape))
print('shape of y_test: ' + str(y_test.shape))
print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))

"""### **One-hot encode the labels**

In the input, a label is a scalar in $\{0, 1, \cdots , 9\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.


"""

def to_one_hot(y, num_class=10):
    y_new = []
    for val in y:
        tempArr = np.zeros(num_class)
        tempArr[val] = 1
        y_new.append(tempArr)
    
    return np.asarray(y_new)
    pass
    
x_train, x_test = x_train.astype('float32') / 255, x_test.astype('float32') / 255
y_train_vec = to_one_hot(y_train)
y_test_vec = to_one_hot(y_test)

print('Shape of y_train_vec: ' + str(y_train_vec.shape))
print('Shape of y_test_vec: ' + str(y_test_vec.shape))

print(y_train[0])
print(y_train_vec[0])

"""**Randomly partition the training set to training and validation sets **
Randomly partition the 50K training samples to 2 sets: 
* a training set containing 40K samples: x_tr, y_tr
* a validation set containing 10K samples: x_val, y_val

"""

from sklearn.model_selection import train_test_split

x_tr, x_val, y_tr, y_val = train_test_split(x_train,y_train_vec,test_size=0.2,shuffle=True)

print('Shape of x_tr: ' + str(x_tr.shape))
print('Shape of y_tr: ' + str(y_tr.shape))
print('Shape of x_val: ' + str(x_val.shape))
print('Shape of y_val: ' + str(y_val.shape))

"""## Building  a CNN and tunning its hyper-parameters





"""

# Build the model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization
from keras.models import Sequential

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (4, 4), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(256, activation='relu'))

model.add(Dense(10, activation='softmax'))

model.summary()

# Define model optimizer and loss function
from tensorflow.keras import optimizers

lr = 0.0001
model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate = lr), metrics=['accuracy'])

# Train the model and store model parameters/loss values
model_1 = model.fit(x_tr, y_tr, batch_size=128, epochs=50, validation_data=(x_val, y_val))
model.save('model_1.h5')

"""## Plot the training and validation loss curve versus epochs."""

model_1.history.keys()

# Plot the loss curve

import matplotlib.pyplot as plt
#%matplotlib inline

loss = model_1.history['loss']
val_loss = model_1.history['val_loss']

plt.xlabel('Epochs')
plt.ylabel('Loss')

epochs = range(len(loss))

plt.plot(epochs, loss, 'red', label='Training loss')
plt.plot(epochs, val_loss, 'green', label='Validation loss')

plt.legend()
plt.show()

# Plot the Accuracy  curve

import matplotlib.pyplot as plt
#%matplotlib inline

accu = model_1.history['accuracy']
val_accu = model_1.history['val_accuracy']

plt.xlabel('Epochs')
plt.ylabel('accu')

epochs = range(len(accu))

plt.plot(epochs, accu, 'red', label='Training Accuracy ')
plt.plot(epochs, val_accu, 'green', label='Validation Accuracy ')

plt.legend()
plt.show()

"""## Train (again) and evaluating the model

### Train the model on the entire training set

Why? Previously, we used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?
"""

#<Compile your model again (using the same hyper-parameters you tuned above)>
model = Sequential()
model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(32, 32, 3)))

model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (4, 4), activation = 'relu'))

model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(256, activation = 'relu'))
model.add(Dense(10, activation='softmax'))


model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(learning_rate = 0.0001) , metrics=['acc'])

#<Train your model on the entire training set (50K samples)>
model_2 = model.fit(x_train, y_train_vec, batch_size=128, epochs=50)
model.save('model_2.h5')

# Plot the loss curve

import matplotlib.pyplot as plt
#%matplotlib inline

loss = model_2.history['loss']


plt.xlabel('Epochs')
plt.ylabel('Loss')

epochs = range(len(loss))

plt.plot(epochs, loss, 'red', label='Training loss')

plt.legend()
plt.show()

# Plot the Accuracy curve

import matplotlib.pyplot as plt
#%matplotlib inline

accu = model_2.history['acc']


plt.xlabel('Epochs')
plt.ylabel('accu')
epochs = range(len(accu))

plt.plot(epochs, accu, 'Green', label='Training accuracy')

plt.legend()
plt.show()

"""**Evaluate the model on the test set**

Do NOT use the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set.
"""

from keras.models import load_model

current_model = load_model('model_1.h5')
Current_acc = current_model.evaluate(x_test, y_test_vec)
print('loss = ' + str(Current_acc[0]))
print('accuracy = ' + str(Current_acc[1]))

current_model = load_model('model_2.h5')
Current_acc = current_model.evaluate(x_test, y_test_vec)
print('loss = ' + str(Current_acc[0]))
print('accuracy = ' + str(Current_acc[1]))